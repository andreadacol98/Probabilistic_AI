
\section{Approximate inference (loopy networks)}
With loopy graphs, BP is often \textbf{overconfident/oscillates}.
\subsection{Variable elimination for MPE (most probable explanation):}

- Given BN and evidence E=e\\
- Choose an ordering of $X_1, ... x_n$\\
- Set up initial factors $f_i=P(X_i|Pa_i)$\\
- For $i=1:n, X_i \notin  E$:\\
$\quad$ - Collect and multiply all factors $f_j$ that include $X_i$\\
$\quad$ - Generate new factor by maximizing out $X_i$:
        $g_i=\underset{w=x_i}{\operatorname{max}}\prod_j f_j$\\
$\quad$ - Add $g$ to set of factors\\
- For $i=n-1:1, X_i\notin E$:
    $\hat{x}_i=\underset{x_i}{\operatorname{argmax}}g_i(x_i, \hat{x}_{i+1:n})$

\textbf{Retrieving MAP from Max-Product (MAP = MPE for a subset of RVs):}\\
- Define max-marginals:\\
    $P_{max}(X_v=x_v):=\underset{x\sim x_v}{\operatorname{max}}P(x)$\\
- For tree factor graphs, max-product computes max-marginals:\\
    $P_{max}(X_v=x_v)	\propto \prod_{u \in N(v)} \mu_{u \rightarrow v}(x_v)$\\
- Can retrieve MAP solution from these (must be careful when ties need to be broken).


\subsection{Sampling based inference: compute marginals as expectations}
\textbf{Hoeffding's inequality:} Suppose $f$ is bounded in $[0, C]$. Then:\\
$P(|E_P[f(X)]-\frac{1}{N}\sum_{i=1}^N f(x_i)|\geq\epsilon) \leq 2exp\big( \frac{-2N\epsilon^2}{C^2}\big)$

\textbf{Monte Carlo Sampling from a BN:}\\
- Sort variables in topological ordering $X_1, X_n$\\
- For $i=1$ to $n$, sample:\\
$x_i \sim P(X_1=x_1, ..., X_{i-1}=x_{i-1})$

\textbf{Rejection Sampling}:\\
- Collect samples over all variables:\\
    $\hat{P}(X_A =x+A | X_B=x_B)=\frac{Count(x_A, x_B)}{Count(x_B)}$\\
- Throw away samples that disagree with $x_B$\\
- Count fraction of $x_a$ on remaining samples


\subsubsection{Directly sampling from the posterior: MCMC}
\textbf{Markov Chain:}: A (stationary) MC is a sequence of RVs $X_1, ..., X_N$, with prior $P(X_1)$ and transition probabilities $P(X_{t+1}|X_t)$ independent of t.\\
\textbf{Markov assumpt.:} $X_{1:t-1}\perp X_{t+1:T}|X_t$, $\forall t>1$\\
\textbf{Stationarity assumption:}\\
$P(X_{t+1}=x|X_t=x')=P(X_{t}=x|X_{t-1}=x')$, $\forall t>1$\\
\textbf{If ergodic} (= there exists a finite t such that every state can be reached in exactly t steps), then: it has a unique and positive stationary distribution $\pi(X)>0$, such for all $x$:\\
            $\underset{N\rightarrow\infty}{lim}P(X_N=x)=\pi(x)$ and $\pi(X)\perp P(X_1)$.\\
If MC satisfies the \textbf{detailed balance equation} (for unnormalized distribution $Q$, for all $x,x'$: $Q(x)P(x'|x)=Q(x')P(x|x')$), then the MC has stationarity distribution $\pi(X)=1/ZQ(X)$.

\textbf{Designing Markov Chains:}\\
- Proposal distribution $R(X'|X)$: given $X_t=x$, sample "proposal" $x'\sim R(X'|X=x)$\\
- Acceptance distribution\\
$\quad$ - Suppose $X_t=x$\\
$\quad$ - With probability $\alpha=min \Big\{1, \frac{Q(x')R(x|x')}{Q(x)R(x'|x)}\Big\}$
        set: $X_{t+1}=x'$\\
$\quad$ - With probability $1-\alpha$, set $X_{t+1}=x$\\

\textbf{MCMC for graphical models: Gibbs sampling (Random Vs \hl{Practical variant}):}\\
- Start with initial assignment $x$ to all variables\\
- Fix observed variables $X_B=x_B$\\
- For $t=1$ to $\infty$, do:\\
$\quad$ - Pick a variable $i$ uniformly at random from $\{1,...,n\}\setminus B$ \hl{/ Set ordering}, and then, for each $X_i$ (except those in $B$)\\
$\quad$ - Set $v_i=$ values of all $x$ except $x_i$\\
$\quad$ - Sample $x_i$ from $P(X_i|v_i)$




