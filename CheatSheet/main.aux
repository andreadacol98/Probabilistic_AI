\relax 
\providecommand\zref@newlabel[2]{}
\bbl@cs{beforestart}
\catcode `"\active 
\babel@aux{ngerman}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Bayesian Regression}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Kalman Filter}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Gaussian Processes}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Gaussian Process Regression}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Kernels}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Optimization of Kernel Parameters}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Aproximation Techniques}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Review of useful concepts and Introduction}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Multivariate Gaussian}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Convex / Jensen's inequality}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Kullback-Leiber divergence}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Review Probability}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Bayesian Networks}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Basic concepts}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Active trails and d-separation}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Exact inference (tree-structured BN) }{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Variable elimination}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Avoiding recomputation: factor graphs}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Sum-product/Belief Propagation (BP) Algorithm:}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Approximate inference}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Laplace Approximation}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Variationa Inverence}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Variable elimination for MPE (most probable explanation):}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Sampling based inference: compute marginals as expectations}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.1}Directly sampling from the posterior: MCMC}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Dynamical models (include time)}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Examples with one variable per time step}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Inference tasks}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Examples with > 1 variable per time step}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Approx. infer. for filtering (DBNs and nonlinear Kalman filters): Particle filtering}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Probabilistic Planning}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Markov Decision Processes}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Policy iteration (Cost $O(S^3+SA\Delta )$)}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Value iteration (Cost $O(SA\Delta )$)}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4}POMDP = Belief-state MDP}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5}Example of approx. solution to POMDPs: Policy gradients}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Learning models from training data}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Learning from i.i.d data}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.1.1}Score based structure learning}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11}Reinforcement Learning}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}Model-based RL}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {11.1.1}$\epsilon $ greedy}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {11.1.2}$R_{max}$ algorithm}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2}Model-free RL: estimate V*(x) directly}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {11.2.1}Q-learning}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3}Gaussian processes}{3}\protected@file@percent }
